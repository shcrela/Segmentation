{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "# 0. Intro"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The aim of this \"document\" is to go trough the steps needed to segment the grains (~10-100nm in diametar) on the images from the AFM.<br>\n",
    "<br>\n",
    "We use Bruker AFM for scanning the surface and all the data treated here comes from this microscope. <br><br>\n",
    "I'll divide the problem into four parts (for now) :\n",
    "- __loading the data__ _(and extracting the parts that interest us)_\n",
    "- __pretreatement__ _(denoising, edge enhancements)_\n",
    "- __segmentation__ _(findig peaks + watershed)_\n",
    "- __statistics__ _(to do...)_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 0.0.1. importing the necessary packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "from ipywidgets import widgets\n",
    "import numpy as np\n",
    "# import pySPM\n",
    "from skimage import io, exposure, img_as_float, filters, restoration, img_as_ubyte, morphology, img_as_uint, measure, segmentation\n",
    "from skimage.morphology import disk\n",
    "from tkinter import filedialog, Tk, messagebox\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy import ndimage\n",
    "import cv2 as cv\n",
    "from warnings import warn\n",
    "\n",
    "# I'll just use this cell for all the imports I will be needing later\n",
    "\n",
    "\n",
    "params = {'phase_image_denoise_footprint':np.ones((5,3)), \n",
    "          'cv_bilateral_filter_spatial_reach':9, \n",
    "          'cv_bilateral_filter_color_reach':70, \n",
    "          'gaussian_blurr_small':3, \n",
    "          'gaussian_blurr_large':7,\n",
    "          'n_iter_closing_edges':3,\n",
    "          'weight_height_edges':5, \n",
    "          'weight_phase_edges':3,\n",
    "          'weight_original_height_image':20, \n",
    "          'n_iter_opening_sharpened_img':2, \n",
    "          'peaks_min_distance':9, \n",
    "          'min_height_extrema':0.37, \n",
    "          'watershed_compactness_param':0.9994}\n",
    "\n",
    "\n",
    "\n",
    "selem = morphology.disk(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": false
   },
   "source": [
    "# 1. Loading Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "There are several possiblities you can use to load your data (results from AFM Bruker @ svi):\n",
    "- loading the image file that was (a bit) pretreated by the nanoscope software (native to Brucker (?))\n",
    "- loading raw .spm (or similar extension) file directly produced by the microscope - __This is the approach to be priviledged in the future__\n",
    " * _one will need to use package like pySPM to be able to load the data in your python program</br> (it proved to be somewhat a hussle to install this package (anaconda installation got messsed-up), so go with it carefully)_\n",
    "- use some other software (like ImageJ/fiji or Gwyddion) to open and/or pretreat the data/image and then save it to format easilly read by python (like .npy (not available) or hdf5!?!)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=blue>**Note:**  It might be worth setting some rules on what to record and what parameters to use when doing AFM scans. Check with Hérvé et Barbara.</font></br>\n",
    "It could help standardise the treatements. Anywhay, one good habit to "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1. ...from _.jpg_ images\n",
    "(produced by nanoscope - the Brucker's software)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/dejan/Documents/python_learning/training/Data/ZnO/E938_NICr_1_ZnOc_100nm_550deg_1h_vide_500n_heigh.jpg\n"
     ]
    }
   ],
   "source": [
    "data_folder = '/home/dejan/Documents/python_learning/training/Data/ZnO/'\n",
    "intermediate_results_folder = '/home/dejan/Documents/python_learning/training/Intermediate_results/'\n",
    "prompt_for_images = 'Choose both height and phase image :'\n",
    "\n",
    "\n",
    "# This is where you chooose the images to treat:\n",
    "\n",
    "root = Tk()\n",
    "root.withdraw()\n",
    "\n",
    "file_path = filedialog.askopenfilenames(initialdir=data_folder, title=prompt_for_images)\n",
    "\n",
    "if len(file_path) != 2:\n",
    "    raise IOError(f'you chose {len(file_path)} file(s) instead of two')\n",
    "\n",
    "name_height = file_path[0].split('/')[-1]\n",
    "name_phase = file_path[1].split('/')[-1]\n",
    "\n",
    "print(file_path[0])\n",
    "\n",
    "if 'phase' not in name_phase[-10:-4]:\n",
    "    warn(f'\\nThe second image contains the string \"{name_phase[-10:-4]}\", where something like \"phase\" is expected\\nYou should double-check your input images')\n",
    "\n",
    "\n",
    "imh = io.imread(file_path[0], as_gray=True)\n",
    "im1 = io.imread(file_path[1], as_gray=True)\n",
    "\n",
    "# This next step had to be added to cope with height and phase images of the different sizes (?). It simply crops the bigger image to the size of the smaller one\n",
    "if im1.shape == imh.shape:\n",
    "    pass\n",
    "else:\n",
    "    common_shape = (min(imh.shape[0], im1.shape[0]),min(imh.shape[1], im1.shape[1]))\n",
    "    im1 = im1[0:common_shape[0], 0:common_shape[1]]\n",
    "    imh = imh[0:common_shape[0], 0:common_shape[1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It should be noted that the images are loaded with dtype=float64. Nevertheless, they only contain positive values, so there would be no significant loss (due to negative values clipping) when converting them to unisigned integers like uint8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "plotting..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('----> The imh image is of shape: {0}, datatype {1}, max: {2}, min: {3}'.format(imh.shape, imh.dtype, np.amax(imh), np.amin(imh)))\n",
    "print('----> The im1 image is of shape: {0}, datatype {1}, max: {2}, min: {3}'.format(im1.shape, im1.dtype, np.amax(im1), np.amin(im1)))\n",
    "\n",
    "# Plotting the images...\n",
    "\n",
    "fig, ax = plt.subplots(ncols=2, nrows=1, sharex=True, sharey=True, frameon=False, figsize=(16, 6))\n",
    "ax[0].imshow(imh, cmap='gray')\n",
    "ax[0].set_title(\"height image\")\n",
    "ax[0].axis('off') # to remove the window frame around the image\n",
    "\n",
    "ax[1].imshow(im1, cmap='gray')\n",
    "ax[1].set_title(\"phase image\")\n",
    "ax[1].axis('off')\n",
    "plt.xticks([]), plt.yticks([])  # to hide tick values on X and Y axis\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2. ...from _Brucker raw files (.spm)_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to read the .spm files, you need to install pySPM package. Just download the whole .zip from GitHub repo, unpack it to the location you want, than open conda prompt in that location and do `python setup.py install` (if  i'm not mistaken).<br><br>\n",
    "Then, you can load the Bruker file via the pySPM python module:\n",
    "[Notebook to read the Bruker raw .spc files](./Read_Bruker.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3. ...from previously reformatted data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": false
   },
   "source": [
    "# 2. Pretreatement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "## 2.1. Extracting the data\n",
    "Depending on your input method, you would need to crop the images, or extract the data in some other way<br><br>\n",
    "**Note:** _information about the length scale is definitly useful, so there should be a way to grab it and store somewhere. The height scale is not really used in this particular problem, but it could be potentially useful to know this ass well (only the heights span is needed as the further transformations of the image would mess up the scale anyway)_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.1. Cropping nanoscope image\n",
    "The images imported from nanoscope have the frame containing infos on scales (color and lengths), which we will not need in the tratements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_afm_bar(im):\n",
    "    \"\"\"\n",
    "    Crop image to remove blank borders and colorbar. Are the dimensions\n",
    "    always the same? To be checked\n",
    "    \"\"\"\n",
    "    return im[22:-56, 4:-50]\n",
    "\n",
    "img0 = crop_afm_bar(imh)\n",
    "imph0 = crop_afm_bar(im1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.2. Choosing the channels from Bruker .spm files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.3. Loading the image files saved by other programs\n",
    "\n",
    "Should be straightforward, depends on the export you've made"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - plotting the images and histograms and checking the data formats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('----> The img image is of shape: {0}, datatype {1}, max: {2}, min: {3}'.format(img.shape, img.dtype, np.amax(img), np.amin(img)))\n",
    "print('----> The imph image is of shape: {0}, datatype {1}, max: {2}, min: {3}'.format(imph.shape, imph.dtype, np.amax(imph), np.amin(imph)))\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(2,2, figsize =(12,8))\n",
    "\n",
    "ax[0,0].imshow(img0, cmap='gray')\n",
    "ax[0,0].set_title(\"height image\")\n",
    "ax[1,0].hist(img0.ravel(), bins=50)\n",
    "# ax[1,0].set_title(\"height image histogram\")\n",
    "ax[0,1].imshow(imph0, cmap='gray')\n",
    "ax[0,1].set_title(\"phase image\")\n",
    "ax[1,1].hist(imph0.ravel(), bins=50)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "in most cases, we would probably like to equilaze histograms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - Saving the pretreated images in standardized format for easier reloading\n",
    "\n",
    "**Note:** _What format to use? For starters, .npy, but should switch to something more descriptive and standardized. hdf5 might be a valid candidate ?!? Would it be worthwhile to create the database of thus standardized data? I could start by creating my own database. Should be carefull on choosing enough metadata (a lot of it is contained already in the headers of Bruker raw files)_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save croped images as numpy binary files (faster to load?):\n",
    "np.save(intermediate_results_folder+'croped_'+name_height[:-4], img0)\n",
    "np.save(intermediate_results_folder+'croped_'+name_phase[:-4], imph0)\n",
    "\n",
    "himg_filename = intermediate_results_folder+'cropped_'+name_height\n",
    "phimg_filename = intermediate_results_folder+'cropped_'+name_phase\n",
    "%store himg_filename\n",
    "\n",
    "# Or, save the same cropped images as .jpg/.png files (smaller space on disk):\n",
    "io.imsave(himg_filename, img0)\n",
    "io.imsave(phimg_filename, imph0)\n",
    "# Attention, saving files to the .png/.jpg format (uint16/uint8) from float64 used when the data was loaded sets off the warning about presision loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2. Histogram equalization and Denoising\n",
    "\n",
    "We have a choice of equilizing the histograms locally or globally. On the denoising side, median filter or/and bilateral filter should be used."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.1. Global histogram equalization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "img=exposure.equalize_hist(img0)\n",
    "imph=exposure.equalize_hist(imph0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "plotting..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('----> The img image is of shape: {0}, datatype {1}, max: {2}, min: {3}'.format(img.shape, img.dtype, np.amax(img), np.amin(img)))\n",
    "print('----> The imph image is of shape: {0}, datatype {1}, max: {2}, min: {3}'.format(imph.shape, imph.dtype, np.amax(imph), np.amin(imph)))\n",
    "\n",
    "ig, ax = plt.subplots(2,2, figsize =(12,8))\n",
    "\n",
    "ax[0,0].imshow(img, cmap='gray')\n",
    "ax[0,0].set_title(\"height image\")\n",
    "ax[1,0].hist(img.ravel(), bins=50)\n",
    "# ax[1,0].set_title(\"height image histogram\")\n",
    "ax[0,1].imshow(imph, cmap='gray')\n",
    "ax[0,1].set_title(\"phase image\")\n",
    "ax[1,1].hist(imph.ravel(), bins=50)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.2. Local histogram equalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "imh_u8 = img_as_ubyte(img0)\n",
    "im1_u8 = img_as_ubyte(imph0)\n",
    "clahe = cv.createCLAHE()\n",
    "imh_u8 = clahe.apply(imh_u8)\n",
    "im1_u8 = clahe.apply(im1_u8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('----> The imh with equalized histogram is of shape: {0}, datatype {1}, max: {2}, min: {3}'.format(imh_u8.shape, imh_u8.dtype, np.amax(imh_u8), np.amin(imh_u8)))\n",
    "print('----> The im1 with equalized histogram is of shape: {0}, datatype {1}, max: {2}, min: {3}'.format(im1_u8.shape, im1_u8.dtype, np.amax(im1_u8), np.amin(im1_u8)))\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(2,2, figsize =(12,8))\n",
    "ax[0,0].imshow(imh_u8, cmap='gray')\n",
    "ax[0,1].imshow(im1_u8, cmap='gray')\n",
    "ax[1,0].hist(imh_u8.ravel(), bins=50)\n",
    "#ax[0,1].imshow(img, cmap='gray')\n",
    "ax[1,1].hist(im1_u8.ravel(), bins=50)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.3. Denoising...using median_filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# I only choose to run the median filter on the phase image, to try to remove the horizontal lines from scans\n",
    "\n",
    "im1_u8 = ndimage.median_filter(im1_u8, footprint = params['phase_image_denoise_footprint'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FigureCanvasNbAgg()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(1,2, figsize =(12,8))\n",
    "ax[0].imshow(im1_u8, cmap='gray')\n",
    "ax[1].imshow(imph0, cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.4. Denoising ...using bilateral filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import skimage.restoration\n",
    "imh_denoised_bilateral = restoration.denoise_bilateral(imh_u8, sigma_color=0.2, sigma_spatial=8, multichannel=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import cv2 as cv\n",
    "img_cdb = cv.bilateralFilter(imh_u8, params['cv_bilateral_filter_spatial_reach'], params['cv_bilateral_filter_color_reach'], params['cv_bilateral_filter_color_reach'])\n",
    "imph_cdb = cv.bilateralFilter(im1_u8,params['cv_bilateral_filter_spatial_reach'], params['cv_bilateral_filter_color_reach'], params['cv_bilateral_filter_color_reach'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "plotting..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FigureCanvasNbAgg()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the resulting images\n",
    "fig, ax = plt.subplots(ncols=2, nrows=2, sharex=True, sharey=True, frameon=False, figsize=(8, 6))\n",
    "ax[0,0].imshow(img0, cmap='gray')\n",
    "ax[0,0].set_title(\"height image\")\n",
    "ax[0,0].axis('off') # to remove the window frame around the image\n",
    "\n",
    "ax[0,1].imshow(imph0, cmap='gray')\n",
    "ax[0,1].set_title(\"phase image\")\n",
    "ax[0,1].axis('off')\n",
    "\n",
    "ax[1,0].imshow(img_cdb, cmap='gray')\n",
    "ax[1,0].set_title(\"img_cdb\")\n",
    "ax[1,0].axis('off') # to remove the window frame around the image\n",
    "\n",
    "ax[1,1].imshow(imph_cdb, cmap='gray')\n",
    "ax[1,1].set_title(\"imph_cdb\")\n",
    "ax[1,1].axis('off')\n",
    "plt.xticks([]), plt.yticks([])  # to hide tick values on X and Y axis\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3. Enhancing the edges / Sharpening"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3.1. ...using the difference of Gaussians"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we try to accentuate the borders by first blurring the image a bit, then substracting the blurred image from the original one which should stress out the edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_edges(img, small_blur = params['gaussian_blurr_small'], large_blur = params['gaussian_blurr_large'], it_max=params['n_iter_closing_edges'], selem=selem):\n",
    "    blurred_small = ndimage.gaussian_filter(img, small_blur)\n",
    "    blurred_large = ndimage.gaussian_filter(img, large_blur)\n",
    "    edges = ~img_as_uint(blurred_large - blurred_small)\n",
    "    edges = clahe.apply(edges)\n",
    "    it=0\n",
    "    while it<it_max:\n",
    "        edges = morphology.closing(edges, selem=selem)\n",
    "        it+=1\n",
    "    edges = 255 * (edges / edges.max())\n",
    "    return(edges)\n",
    "\n",
    "edges = find_edges(img_cdb)\n",
    "edges_phase = find_edges(img_cdb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.2. ...or using *skimage.enhance_contrast*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from skimage import filters\n",
    "# from skimage.morphology import disk\n",
    "\n",
    "imh_sharpened_eh = filters.rank.enhance_contrast(img_cdb, disk(2))\n",
    "im1_sharpened_eh = filters.rank.enhance_contrast(imph_cdb, disk(2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "plotting..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Plot the resulting images\n",
    "fig, ax = plt.subplots(ncols=2, nrows=2, sharex=True, sharey=True, frameon=False, figsize=(12, 8))\n",
    "ax[0,0].imshow(img_cdb, cmap='gray')\n",
    "ax[0,0].set_title(\"height image denoised\")\n",
    "ax[0,0].axis('off') # to remove the window frame around the image\n",
    "\n",
    "ax[0,1].imshow(imph_cdb, cmap='gray')\n",
    "ax[0,1].set_title(\"phase image denoised\")\n",
    "ax[0,1].axis('off')\n",
    "\n",
    "ax[1,0].imshow(edges, cmap='gray')\n",
    "ax[1,0].set_title(\"edges on height denoised image\")\n",
    "ax[1,0].axis('off') # to remove the window frame around the image\n",
    "\n",
    "ax[1,1].imshow(edges_phase, cmap='gray')\n",
    "ax[1,1].set_title(\"edges on phase denoised image\")\n",
    "ax[1,1].axis('off')\n",
    "plt.xticks([]), plt.yticks([])  # to hide tick values on X and Y axis\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4. Constructing the combined image wich will be the base for the rest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dejan/anaconda3/envs/segmentation/lib/python3.7/site-packages/skimage/util/dtype.py:190: UserWarning: Downcasting int32 to uint16 without scaling because max value 5084 fits in uint16\n",
      "  \"value {} fits in {}\".format(a.dtype, dtype, a.max(), dtype))\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# enhancing the edges on the denoised height image by substracting the difference of gaussians from both phase and height images (wighted: \n",
    "\n",
    "koka = img_as_uint(params['weight_original_height_image']*np.asarray(img_cdb, dtype=np.int32) - params['weight_height_edges']*np.asarray(edges, dtype=np.int32) - params['weight_phase_edges']*np.asarray(edges_phase, dtype=np.int32))\n",
    "# img_as_uint clips the negative values to zero\n",
    "#print(f'min koka = {koka.min()}, max koka = {koka.max()}')\n",
    "\n",
    "\n",
    "sharp_gauss = 255 * (koka / koka.max()) # this is the image that we will use to find the grains (uint8)\n",
    "\n",
    "\n",
    "# we should bare in mind that the size of the grains is rather enlarged on the AFM images,\n",
    "# as a result of the scanning probe size, so opening a bit won't hurt, and might permit resolving the grains better\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "# 3. Marking the grains"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1. Creating masks...\n",
    "  from the combined image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#----------------------Testing different masks-----------------------------------\n",
    "win_size = 61\n",
    "koef_sigma = 0.003\n",
    "\n",
    "thresh_loc = filters.threshold_local(sharp_gauss, win_size, method='gaussian', offset=0.1, mode='reflect', param=7)\n",
    "thresh_li = filters.threshold_li(sharp_gauss)\n",
    "thresh_nib = filters.threshold_niblack(sharp_gauss, window_size=win_size, k=koef_sigma)\n",
    "thresh_sau = filters.threshold_sauvola(sharp_gauss, window_size=win_size, k=koef_sigma, r=None)\n",
    "thresh_otsu = filters.threshold_otsu(sharp_gauss, nbins=256)\n",
    "\n",
    "mask_li = sharp_gauss > thresh_li\n",
    "mask_nib = sharp_gauss > thresh_nib\n",
    "mask_sau = sharp_gauss > thresh_sau\n",
    "mask_otsu = sharp_gauss > thresh_otsu\n",
    "mask_loc = sharp_gauss > thresh_loc\n",
    "\n",
    "mask = mask_nib # settling with one of the above\n",
    "morphology.remove_small_holes(mask, 96, connectivity=1, in_place=True)\n",
    "# =============================================================================\n",
    "#     There is a problem with local threshold filter:\n",
    "#     In the areas where is a high-level plateau, using this threshold,\n",
    "#     There are some blanks obtained even though it is clearly not the background\n",
    "#     So after all, back to the global threshold\n",
    "# =============================================================================\n",
    "\n",
    "\n",
    "\n",
    "it=0\n",
    "while it<params['n_iter_opening_sharpened_img']:\n",
    "    mask = morphology.opening(mask, selem = selem)\n",
    "    it+=1\n",
    "    \n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2. Creating the distance map on the combined image..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting the map of the distances from the background on the mask:\n",
    "distance_map = ndimage.distance_transform_edt(mask)\n",
    "#distance_map = exposure.rescale_intensity(distance_map)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3. Finding peaks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'peaks_height_indices' (ndarray)\n"
     ]
    }
   ],
   "source": [
    "footprint = morphology.disk(9)\n",
    "def find_peaks_ongrains(img, footprint=footprint, labels=mask, connectivity=2, selem=selem):\n",
    "    peaks = feature.peak_local_max(img, footprint=footprint, labels=mask, indices=False)\n",
    "    peaks = morphology.binary_dilation(peaks, selem=selem)\n",
    "    peak_labels = measure.label(peaks)\n",
    "    peak_indices = feature.peak_local_max(img, footprint=footprint, labels=mask, indices=True)\n",
    "    return peaks, peak_labels, peak_indices\n",
    "\n",
    "\n",
    "#------------------Finding  peaks using the distance map--------------------------------\n",
    "# peaks are then set as the points the furthest away (spatially, not by intenisty) from the background \n",
    "#(this might be especially convinient for some images where the brightest spots are close to the grain edges)\n",
    "\n",
    "peaks, peak_labels, peak_indices = find_peaks_ongrains(distance_map)\n",
    "\n",
    "\n",
    "#-------------- Finding peaks from sharpened image (diff of gauss)-------------\n",
    "#---------------- based on heights (grayscale values) -------------------------\n",
    "\n",
    "peaks_height, peaks_height_labels, peaks_height_indices = find_peaks_ongrains(sharp_gauss)\n",
    "\n",
    "%store peaks_height_indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4. Labelizig the grains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "#----------------------------------------------------------------------------------\n",
    "\n",
    "# watershedding:\n",
    "\n",
    "def find_grains_onpeaks(peak_labels, img=-sharp_gauss, compactness=params['watershed_compactness_param'], watershed_line=True, mask=mask):\n",
    "    _grain_labels = morphology.watershed(img, peak_labels, compactness = compactness, mask=mask, watershed_line=watershed_line)\n",
    "    _grain_labels = segmentation.clear_border(_grain_labels)\n",
    "    new_order = np.random.permutation(np.arange(101, _grain_labels.max()+102))\n",
    "    new_labels = new_order[_grain_labels]\n",
    "    new_labels[mask==0]=0\n",
    "    new_labels = segmentation.clear_border(new_labels)\n",
    "    return new_labels\n",
    "    \n",
    "\n",
    "grains = find_grains_onpeaks(peak_labels) # from the distance map\n",
    "grains_height = find_grains_onpeaks(peaks_height_labels) # from sharp_gauss height values\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Plotting..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f567c8541fa74764ae0f7ba3ecac9286",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(FloatSlider(value=0.3, description='alpha_grains', max=0.6), Output()), _dom_classes=('w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "alpha_grains = 0.22\n",
    "alpha_peaks = 0.1\n",
    "@widgets.interact(alpha_grains=(0.0,0.6))\n",
    "def plot_ilustration(alpha_grains):\n",
    "    plt.close('all')\n",
    "    fig, ax = plt.subplots(ncols=3, nrows=2, sharex=True, sharey=True, frameon=False, figsize=(12, 8))\n",
    "\n",
    "    ax[0,0].imshow(img, cmap='gray')\n",
    "    ax[0,0].set_title(\"original height image\")\n",
    "\n",
    "    ax[0,1].imshow(sharp_gauss)\n",
    "    ax[0,1].set_title(f\"sharp_gauss \\n combined image used for grain detection\")#win size={win_size}, k={koef_sigma}\")\n",
    "\n",
    "    ax[0,2].imshow(imph, cmap='gray')\n",
    "    ax[0,2].set_title(\"original phase image\")\n",
    "\n",
    "\n",
    "    ax[1,0].imshow(img, cmap='gray')\n",
    "    ax[1,0].imshow(grains, cmap='tab20b', alpha=alpha_grains)\n",
    "    ax[1,0].contour(peaks, colors='green', alpha=alpha_peaks)\n",
    "    ax[1,0].set_title(\"grains traced on top of the original height image\\n seed: find_loc_max on mask distance map\")\n",
    "\n",
    "    #imshow(grains_height, cmap='nipy_spectral')\n",
    "\n",
    "    ax[1,1].imshow(mask, cmap='gray')\n",
    "    ax[1,1].set_title(\"mask\")#distance map used to find peaks on the left\")\n",
    "\n",
    "\n",
    "    ax[1,2].imshow(img, cmap='gray')\n",
    "    ax[1,2].contour(peaks_height, colors='yellow', alpha=alpha_peaks)\n",
    "    ax[1,2].imshow(grains_height, cmap='tab20b', alpha=alpha_grains)\n",
    "    ax[1,2].set_title(\"grains traced on top of the original height image\\n seed: find_loc_max on sharp_gauss\")\n",
    "\n",
    "    axis = ax.ravel()\n",
    "    for a in axis:\n",
    "        a.axis('off') # to remove the window frame around the image\n",
    "\n",
    "    #plt.xticks([]), plt.yticks([])  # to hide tick values on X and Y axis\n",
    "    plt.tight_layout()\n",
    "    plt.show()                                                                                  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Extras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "019fb9352fb045dcba4c0302a7ddf217",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=31, description='win_size', max=131, min=9, step=2), FloatSlider(value=0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@widgets.interact(win_size=widgets.IntSlider(min=9,max=131, step=2, value=31), koef_sigma=(-0.95,0.95))\n",
    "def alh_ph(win_size,koef_sigma):\n",
    "    plt.close('all')\n",
    "    thresh_nib = filters.threshold_niblack(sharp_gauss, window_size=win_size, k=koef_sigma)\n",
    "    mask_nib = sharp_gauss > thresh_nib\n",
    "    plt.figure(figsize=(12,6))\n",
    "    #plt.imshow(kanali, cmap='gray')\n",
    "    plt.imshow(mask_nib, cmap='gray')\n",
    "    #plt.imshow(mmm, cmap='spring', alpha = a)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c6248bd5db64ea7af42af299452b9aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Figure(axes=[Axis(scale=LinearScale()), Axis(orientation='vertical', scale=LinearScale())], fig…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display\n",
    "from bqplot import pyplot as bqp\n",
    "\n",
    "x_data = peaks_height_indices[:,0]\n",
    "y_data = peaks_height_indices[:,1]\n",
    "\n",
    "\n",
    "bqp.figure(title='Illustration of peak reajustement')#, background_style = {'background':'url('+himg_filename+')', 'background-size': 'contain', 'opacity':0.5}) # {'background_image': height_image})\n",
    "#slika = bqp.imshow(height_image, 'height')\n",
    "scatter_plot = bqp.scatter(x_data, y_data)\n",
    "bqp.show()\n",
    "\n",
    "output = widgets.Output() \n",
    "@output.capture()\n",
    "def foo(change):\n",
    "    #print(f'the y_data has changed from {change.old} to {change.new}')\n",
    "    print(change.new)\n",
    "\n",
    "scatter_plot.observe(foo, 'y')\n",
    "scatter_plot.enable_move = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "#display(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
